{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb7cc47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ EXECUTING VERTEX AI EXTRACTION PIPELINE\n",
      "============================================================\n",
      "üöÄ VERTEX AI GEOTECHNICAL DATA EXTRACTION SYSTEM\n",
      "======================================================================\n",
      "‚úÖ Vertex AI Gemini configured successfully with service account\n",
      "\n",
      "üöÄ Creating Vertex AI Geotechnical Dataset\n",
      "============================================================\n",
      "üîç Found 6 PDF files\n",
      "  ‚úÖ Complete Report: 7144-25\n",
      "  ‚úÖ Complete Report: 7145-25\n",
      "  ‚úÖ Complete Report: 7155-25\n",
      "  ‚úÖ Text Plot: 7155-25\n",
      "  ‚úÖ Complete Report: 7157-25\n",
      "  ‚úÖ Text Plot: 7157-25\n",
      "\n",
      "üìä Summary: 4 Complete Reports, 2 Text Plots\n",
      "\n",
      "üîÑ Processing 4 projects with Vertex AI...\n",
      "\n",
      "ü§ñ Processing Project 7144-25 with Vertex AI\n",
      "  üìä Analyzing Complete Report...\n",
      "  üìÑ Extracted 53844 characters from PDF\n",
      "  ü§ñ Analyzing with Vertex AI Gemini...\n",
      "    ‚úÖ bearing_capacity: 0.7\n",
      "    ‚úÖ foundation_type: Strip\n",
      "    ‚úÖ spt_n_value: 13.0\n",
      "    ‚úÖ uscs_classification: GM\n",
      "    ‚úÖ consistency: stiff\n",
      "    ‚úÖ soil_color: brown\n",
      "    ‚úÖ moisture_condition: moist\n",
      "  ‚úÖ Vertex AI extraction successful\n",
      "\n",
      "ü§ñ Processing Project 7145-25 with Vertex AI\n",
      "  üìä Analyzing Complete Report...\n",
      "  üìÑ Extracted 52504 characters from PDF\n",
      "  ü§ñ Analyzing with Vertex AI Gemini...\n",
      "    ‚úÖ bearing_capacity: 0.75\n",
      "    ‚úÖ foundation_type: Strip\n",
      "    ‚úÖ spt_n_value: 51.0\n",
      "    ‚úÖ uscs_classification: GM\n",
      "    ‚úÖ consistency: dense\n",
      "    ‚úÖ soil_color: brown\n",
      "    ‚úÖ moisture_condition: dry\n",
      "  ‚úÖ Vertex AI extraction successful\n",
      "\n",
      "ü§ñ Processing Project 7155-25 with Vertex AI\n",
      "  üìã Analyzing Text Plot...\n",
      "  üìÑ Extracted 20492 characters from PDF\n",
      "  ü§ñ Analyzing with Vertex AI Gemini...\n",
      "    ‚úÖ spt_n_value: 22.0\n",
      "    ‚ö†Ô∏è uscs_classification: CL-ML not in valid options\n",
      "    ‚úÖ consistency: hard\n",
      "    ‚úÖ soil_color: brown\n",
      "    ‚úÖ moisture_condition: moist\n",
      "  ‚úÖ Vertex AI extraction successful\n",
      "  üìä Analyzing Complete Report...\n",
      "  üìÑ Extracted 99396 characters from PDF\n",
      "  ü§ñ Analyzing with Vertex AI Gemini...\n",
      "    ‚ö†Ô∏è uscs_classification: CL-ML not in valid options\n",
      "    ‚úÖ consistency: hard\n",
      "    ‚úÖ soil_color: brown\n",
      "    ‚úÖ moisture_condition: moist\n",
      "  ‚úÖ Vertex AI extraction successful\n",
      "\n",
      "ü§ñ Processing Project 7157-25 with Vertex AI\n",
      "  üìã Analyzing Text Plot...\n",
      "  üìÑ Extracted 31181 characters from PDF\n",
      "  ü§ñ Analyzing with Vertex AI Gemini...\n",
      "    ‚úÖ bearing_capacity: 0.75\n",
      "    ‚úÖ foundation_type: Strip\n",
      "    ‚úÖ uscs_classification: CL\n",
      "    ‚úÖ consistency: firm\n",
      "    ‚úÖ soil_color: brown\n",
      "    ‚úÖ moisture_condition: moist\n",
      "  ‚úÖ Vertex AI extraction successful\n",
      "  üìä Analyzing Complete Report...\n",
      "  üìÑ Extracted 90739 characters from PDF\n",
      "  ü§ñ Analyzing with Vertex AI Gemini...\n",
      "    ‚úÖ bearing_capacity: 0.75\n",
      "    ‚úÖ foundation_type: Strip\n",
      "    ‚úÖ uscs_classification: CL\n",
      "    ‚úÖ consistency: firm\n",
      "    ‚úÖ soil_color: brown\n",
      "    ‚úÖ moisture_condition: moist\n",
      "  ‚úÖ Vertex AI extraction successful\n",
      "\n",
      "‚úÖ Vertex AI dataset created: 4 projects √ó 8 features\n",
      "\n",
      "üíæ Dataset saved as: geotechnical_dataset_vertex_ai.csv\n",
      "\n",
      "üìä VERTEX AI EXTRACTION SUMMARY:\n",
      "   Projects processed: 4\n",
      "   Features extracted: 7\n",
      "   ‚úÖ bearing_capacity         : 3/4 (75%)\n",
      "   ‚úÖ foundation_type          : 3/4 (75%)\n",
      "   ‚ö†Ô∏è spt_n_value              : 2/4 (50%)\n",
      "   ‚úÖ uscs_classification      : 3/4 (75%)\n",
      "   ‚úÖ consistency              : 4/4 (100%)\n",
      "   ‚úÖ soil_color               : 4/4 (100%)\n",
      "   ‚úÖ moisture_condition       : 4/4 (100%)\n",
      "\n",
      "üìã DATASET PREVIEW:\n",
      "  project_id  bearing_capacity foundation_type  spt_n_value uscs_classification consistency soil_color moisture_condition\n",
      "0    7144-25              0.70           Strip         13.0                  GM       stiff      brown              moist\n",
      "1    7145-25              0.75           Strip         51.0                  GM       dense      brown                dry\n",
      "2    7155-25               NaN             NaN          NaN                 NaN        hard      brown              moist\n",
      "3    7157-25              0.75           Strip          NaN                  CL        firm      brown              moist\n",
      "\n",
      "üéØ READY FOR AI/ML MODELING!\n",
      "\n",
      "üéâ SUCCESS! Vertex AI extraction completed!\n",
      "üìä Dataset shape: (4, 8)\n",
      "\n",
      "üèÅ PIPELINE COMPLETE!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "# PDF processing libraries\n",
    "import pdfplumber\n",
    "import PyPDF2\n",
    "\n",
    "# Vertex AI imports (instead of google.generativeai)\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, SafetySetting, HarmCategory, HarmBlockThreshold\n",
    "\n",
    "# Configure display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "class VertexAIGeotechnicalExtractor:\n",
    "    \"\"\"\n",
    "    Advanced Geotechnical Data Extractor using Vertex AI Gemini\n",
    "    Uses service account credentials for authentication\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_directory: str, credentials_file: str):\n",
    "        self.data_dir = Path(data_directory)\n",
    "        self.setup_vertex_ai(credentials_file)\n",
    "        self.complete_reports = []\n",
    "        self.text_plots = []\n",
    "        \n",
    "        # Define comprehensive feature schema\n",
    "        self.extraction_schema = {\n",
    "            \"bearing_capacity\": {\n",
    "                \"description\": \"Allowable bearing capacity in T/ft¬≤ or Tonne/ft¬≤\",\n",
    "                \"type\": \"float\",\n",
    "                \"range\": [0.1, 50.0]\n",
    "            },\n",
    "            \"foundation_type\": {\n",
    "                \"description\": \"Type of foundation recommended\",\n",
    "                \"type\": \"string\",\n",
    "                \"options\": [\"Strip\", \"Raft\", \"Pile\", \"Isolated\", \"Unknown\"]\n",
    "            },\n",
    "            \"liquid_limit_ll\": {\n",
    "                \"description\": \"Liquid limit percentage from Atterberg limits\",\n",
    "                \"type\": \"float\",\n",
    "                \"range\": [15.0, 100.0]\n",
    "            },\n",
    "            \"plastic_limit_pl\": {\n",
    "                \"description\": \"Plastic limit percentage from Atterberg limits\",\n",
    "                \"type\": \"float\",\n",
    "                \"range\": [10.0, 50.0]\n",
    "            },\n",
    "            \"plasticity_index\": {\n",
    "                \"description\": \"Plasticity index (LL - PL)\",\n",
    "                \"type\": \"float\",\n",
    "                \"range\": [0.0, 50.0]\n",
    "            },\n",
    "            \"moisture_content_pct\": {\n",
    "                \"description\": \"Natural moisture content percentage\",\n",
    "                \"type\": \"float\",\n",
    "                \"range\": [0.0, 60.0]\n",
    "            },\n",
    "            \"sand_pct\": {\n",
    "                \"description\": \"Sand percentage from grain size analysis\",\n",
    "                \"type\": \"float\",\n",
    "                \"range\": [0.0, 100.0]\n",
    "            },\n",
    "            \"gravel_pct\": {\n",
    "                \"description\": \"Gravel percentage from grain size analysis\",\n",
    "                \"type\": \"float\",\n",
    "                \"range\": [0.0, 100.0]\n",
    "            },\n",
    "            \"fines_pct\": {\n",
    "                \"description\": \"Fines percentage (passing #200 sieve)\",\n",
    "                \"type\": \"float\",\n",
    "                \"range\": [0.0, 100.0]\n",
    "            },\n",
    "            \"spt_n_value\": {\n",
    "                \"description\": \"Standard Penetration Test N-values\",\n",
    "                \"type\": \"float\",\n",
    "                \"range\": [0.0, 100.0]\n",
    "            },\n",
    "            \"uscs_classification\": {\n",
    "                \"description\": \"Unified Soil Classification System\",\n",
    "                \"type\": \"string\",\n",
    "                \"options\": [\"CL\", \"CH\", \"ML\", \"MH\", \"SM\", \"SC\", \"SW\", \"SP\", \"GW\", \"GP\", \"GM\", \"GC\"]\n",
    "            },\n",
    "            \"bulk_density\": {\n",
    "                \"description\": \"Bulk/dry density in g/cm¬≥\",\n",
    "                \"type\": \"float\",\n",
    "                \"range\": [1.0, 2.5]\n",
    "            },\n",
    "            \"specific_gravity\": {\n",
    "                \"description\": \"Specific gravity of soil solids\",\n",
    "                \"type\": \"float\",\n",
    "                \"range\": [2.4, 2.8]\n",
    "            },\n",
    "            \"consistency\": {\n",
    "                \"description\": \"Soil consistency description\",\n",
    "                \"type\": \"string\",\n",
    "                \"options\": [\"soft\", \"firm\", \"stiff\", \"hard\", \"very soft\", \"very stiff\", \"loose\", \"dense\"]\n",
    "            },\n",
    "            \"soil_color\": {\n",
    "                \"description\": \"Visual color of soil\",\n",
    "                \"type\": \"string\",\n",
    "                \"options\": [\"brown\", \"gray\", \"grey\", \"red\", \"yellow\", \"black\", \"white\", \"orange\"]\n",
    "            },\n",
    "            \"moisture_condition\": {\n",
    "                \"description\": \"Moisture state of soil\",\n",
    "                \"type\": \"string\",\n",
    "                \"options\": [\"dry\", \"moist\", \"wet\", \"saturated\", \"damp\"]\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def setup_vertex_ai(self, credentials_file: str):\n",
    "        \"\"\"Initialize Vertex AI using service account credentials\"\"\"\n",
    "        try:\n",
    "            # Set the environment variable for authentication\n",
    "            os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = credentials_file\n",
    "            \n",
    "            # Load project ID from credentials file\n",
    "            with open(credentials_file, 'r') as f:\n",
    "                credentials = json.load(f)\n",
    "            \n",
    "            project_id = credentials.get('project_id', 'aiml-365220')\n",
    "            \n",
    "            # Initialize Vertex AI\n",
    "            vertexai.init(\n",
    "                project=project_id,\n",
    "                location=\"us-central1\"  # You can change this if needed\n",
    "            )\n",
    "            \n",
    "            # Initialize the Gemini model\n",
    "            self.model = GenerativeModel(\"gemini-1.5-pro\")\n",
    "            \n",
    "            # Test the connection\n",
    "            test_response = self.model.generate_content(\"Hello, test connection\")\n",
    "            print(\"‚úÖ Vertex AI Gemini configured successfully with service account\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error setting up Vertex AI: {e}\")\n",
    "            print(\"üí° Make sure you have the correct service account permissions\")\n",
    "            self.model = None\n",
    "    \n",
    "    def identify_file_types(self):\n",
    "        \"\"\"Identify and categorize PDF files\"\"\"\n",
    "        all_files = list(self.data_dir.glob(\"*.pdf\"))\n",
    "        \n",
    "        print(f\"üîç Found {len(all_files)} PDF files\")\n",
    "        \n",
    "        for file in all_files:\n",
    "            filename = file.name.lower()\n",
    "            \n",
    "            # Extract project ID pattern\n",
    "            project_id_match = re.search(r'(\\d{4}\\s*-\\s*\\d{2})', filename)\n",
    "            if not project_id_match:\n",
    "                continue\n",
    "                \n",
    "            clean_id = project_id_match.group(1).replace(' ', '')\n",
    "            \n",
    "            if \"complete report\" in filename:\n",
    "                self.complete_reports.append({\n",
    "                    'project_id': clean_id,\n",
    "                    'file_path': file,\n",
    "                    'type': 'complete_report'\n",
    "                })\n",
    "                print(f\"  ‚úÖ Complete Report: {clean_id}\")\n",
    "                \n",
    "            elif \"text plot\" in filename:\n",
    "                self.text_plots.append({\n",
    "                    'project_id': clean_id,\n",
    "                    'file_path': file,\n",
    "                    'type': 'text_plot'\n",
    "                })\n",
    "                print(f\"  ‚úÖ Text Plot: {clean_id}\")\n",
    "        \n",
    "        print(f\"\\nüìä Summary: {len(self.complete_reports)} Complete Reports, {len(self.text_plots)} Text Plots\")\n",
    "        return self.complete_reports, self.text_plots\n",
    "    \n",
    "    def extract_pdf_text_comprehensive(self, pdf_file) -> str:\n",
    "        \"\"\"Extract comprehensive text from PDF\"\"\"\n",
    "        full_text = \"\"\n",
    "        \n",
    "        try:\n",
    "            with pdfplumber.open(pdf_file) as pdf:\n",
    "                for page_num, page in enumerate(pdf.pages):\n",
    "                    page_text = page.extract_text()\n",
    "                    if page_text:\n",
    "                        full_text += f\"\\n--- PAGE {page_num + 1} ---\\n\"\n",
    "                        full_text += page_text + \"\\n\"\n",
    "                    \n",
    "                    # Extract tables separately\n",
    "                    tables = page.extract_tables()\n",
    "                    if tables:\n",
    "                        for table_num, table in enumerate(tables):\n",
    "                            full_text += f\"\\n--- TABLE {table_num + 1} ON PAGE {page_num + 1} ---\\n\"\n",
    "                            for row in table:\n",
    "                                if row:\n",
    "                                    full_text += \" | \".join([str(cell) if cell else \"\" for cell in row]) + \"\\n\"\n",
    "            \n",
    "            print(f\"  üìÑ Extracted {len(full_text)} characters from PDF\")\n",
    "            return full_text\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error extracting PDF text: {e}\")\n",
    "            return \"\"\n",
    "    \n",
    "    def create_extraction_prompt(self, pdf_text: str, project_id: str) -> str:\n",
    "        \"\"\"Create comprehensive extraction prompt\"\"\"\n",
    "        \n",
    "        feature_descriptions = []\n",
    "        for feature, config in self.extraction_schema.items():\n",
    "            desc = f\"- **{feature}**: {config['description']}\"\n",
    "            if config['type'] == 'float':\n",
    "                desc += f\" (Range: {config['range'][0]}-{config['range'][1]})\"\n",
    "            elif 'options' in config:\n",
    "                desc += f\" (Options: {', '.join(config['options'])})\"\n",
    "            feature_descriptions.append(desc)\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "You are an expert geotechnical engineer analyzing a soil investigation report for Project {project_id}.\n",
    "\n",
    "EXTRACT THE FOLLOWING GEOTECHNICAL PARAMETERS:\n",
    "\n",
    "{chr(10).join(feature_descriptions)}\n",
    "\n",
    "EXTRACTION RULES:\n",
    "1. **ACCURACY**: Only extract values you are confident about\n",
    "2. **VALIDATION**: Ensure values are within realistic ranges\n",
    "3. **FOUNDATION TYPE PRIORITY**: If multiple types mentioned, prioritize recommendations\n",
    "4. **BEARING CAPACITY**: Look for allowable/safe bearing capacity, not ultimate\n",
    "5. **GRAIN SIZE**: Extract from sieve analysis tables\n",
    "6. **ATTERBERG LIMITS**: Extract LL, PL, and calculate PI = LL - PL if not given\n",
    "7. **SPT VALUES**: Extract Standard Penetration Test N-values from borehole logs\n",
    "8. **MULTIPLE VALUES**: If multiple values exist, provide the most representative one\n",
    "\n",
    "RESPONSE FORMAT:\n",
    "Return ONLY a valid JSON object with these exact keys (use null for missing data):\n",
    "\n",
    "{{\n",
    "    \"bearing_capacity\": float or null,\n",
    "    \"foundation_type\": string or null,\n",
    "    \"liquid_limit_ll\": float or null,\n",
    "    \"plastic_limit_pl\": float or null,\n",
    "    \"plasticity_index\": float or null,\n",
    "    \"moisture_content_pct\": float or null,\n",
    "    \"sand_pct\": float or null,\n",
    "    \"gravel_pct\": float or null,\n",
    "    \"fines_pct\": float or null,\n",
    "    \"spt_n_value\": float or null,\n",
    "    \"uscs_classification\": string or null,\n",
    "    \"bulk_density\": float or null,\n",
    "    \"specific_gravity\": float or null,\n",
    "    \"consistency\": string or null,\n",
    "    \"soil_color\": string or null,\n",
    "    \"moisture_condition\": string or null\n",
    "}}\n",
    "\n",
    "GEOTECHNICAL REPORT TEXT:\n",
    "{pdf_text[:15000]}\n",
    "\n",
    "Extract the data now:\n",
    "\"\"\"\n",
    "        return prompt\n",
    "    \n",
    "    def extract_with_vertex_ai(self, pdf_text: str, project_id: str) -> Optional[Dict]:\n",
    "        \"\"\"Extract geotechnical data using Vertex AI Gemini\"\"\"\n",
    "        if not self.model:\n",
    "            print(\"‚ùå Vertex AI model not available\")\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            print(f\"  ü§ñ Analyzing with Vertex AI Gemini...\")\n",
    "            \n",
    "            # Create extraction prompt\n",
    "            prompt = self.create_extraction_prompt(pdf_text, project_id)\n",
    "            \n",
    "            # Generate response with retry logic\n",
    "            max_retries = 3\n",
    "            for attempt in range(max_retries):\n",
    "                try:\n",
    "                    response = self.model.generate_content(prompt)\n",
    "                    response_text = response.text.strip()\n",
    "                    \n",
    "                    # Clean response (remove markdown formatting)\n",
    "                    if response_text.startswith('```json'):\n",
    "                        response_text = response_text[7:]\n",
    "                    if response_text.endswith('```'):\n",
    "                        response_text = response_text[:-3]\n",
    "                    \n",
    "                    # Parse JSON\n",
    "                    extracted_data = json.loads(response_text)\n",
    "                    \n",
    "                    # Validate extracted data\n",
    "                    validated_data = self.validate_extraction(extracted_data)\n",
    "                    \n",
    "                    print(f\"  ‚úÖ Vertex AI extraction successful\")\n",
    "                    return validated_data\n",
    "                    \n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"  ‚ö†Ô∏è JSON parsing error (attempt {attempt + 1}): {e}\")\n",
    "                    if attempt == max_retries - 1:\n",
    "                        return None\n",
    "                    time.sleep(1)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"  ‚ö†Ô∏è Vertex AI error (attempt {attempt + 1}): {e}\")\n",
    "                    if attempt == max_retries - 1:\n",
    "                        return None\n",
    "                    time.sleep(2)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Vertex AI extraction error: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def validate_extraction(self, data: Dict) -> Dict:\n",
    "        \"\"\"Validate and clean extracted data\"\"\"\n",
    "        validated = {}\n",
    "        \n",
    "        for feature, value in data.items():\n",
    "            if feature not in self.extraction_schema:\n",
    "                continue\n",
    "                \n",
    "            config = self.extraction_schema[feature]\n",
    "            \n",
    "            if value is None:\n",
    "                validated[feature] = None\n",
    "                continue\n",
    "            \n",
    "            # Validate numeric values\n",
    "            if config['type'] == 'float':\n",
    "                try:\n",
    "                    float_val = float(value)\n",
    "                    min_val, max_val = config['range']\n",
    "                    \n",
    "                    if min_val <= float_val <= max_val:\n",
    "                        validated[feature] = float_val\n",
    "                        print(f\"    ‚úÖ {feature}: {float_val}\")\n",
    "                    else:\n",
    "                        print(f\"    ‚ö†Ô∏è {feature}: {float_val} outside range {min_val}-{max_val}\")\n",
    "                        validated[feature] = None\n",
    "                except (ValueError, TypeError):\n",
    "                    print(f\"    ‚ö†Ô∏è {feature}: Invalid numeric value {value}\")\n",
    "                    validated[feature] = None\n",
    "            \n",
    "            # Validate string values\n",
    "            elif config['type'] == 'string':\n",
    "                str_val = str(value).strip()\n",
    "                if 'options' in config:\n",
    "                    if str_val in config['options']:\n",
    "                        validated[feature] = str_val\n",
    "                        print(f\"    ‚úÖ {feature}: {str_val}\")\n",
    "                    else:\n",
    "                        print(f\"    ‚ö†Ô∏è {feature}: {str_val} not in valid options\")\n",
    "                        validated[feature] = None\n",
    "                else:\n",
    "                    validated[feature] = str_val\n",
    "                    print(f\"    ‚úÖ {feature}: {str_val}\")\n",
    "        \n",
    "        # Calculate plasticity index if LL and PL are available\n",
    "        if (validated.get('liquid_limit_ll') is not None and \n",
    "            validated.get('plastic_limit_pl') is not None and \n",
    "            validated.get('plasticity_index') is None):\n",
    "            \n",
    "            pi = validated['liquid_limit_ll'] - validated['plastic_limit_pl']\n",
    "            if 0 <= pi <= 50:\n",
    "                validated['plasticity_index'] = pi\n",
    "                print(f\"    ‚úÖ plasticity_index: {pi} (calculated)\")\n",
    "        \n",
    "        return validated\n",
    "    \n",
    "    def process_project(self, project_id: str) -> Dict:\n",
    "        \"\"\"Process a single project\"\"\"\n",
    "        print(f\"\\nü§ñ Processing Project {project_id} with Vertex AI\")\n",
    "        \n",
    "        # Find files for this project\n",
    "        complete_report = next((cr for cr in self.complete_reports if cr['project_id'] == project_id), None)\n",
    "        text_plot = next((tp for tp in self.text_plots if tp['project_id'] == project_id), None)\n",
    "        \n",
    "        project_data = {'project_id': project_id}\n",
    "        \n",
    "        # Process Text Plot (for bearing capacity and foundation type)\n",
    "        if text_plot:\n",
    "            print(f\"  üìã Analyzing Text Plot...\")\n",
    "            text_plot_content = self.extract_pdf_text_comprehensive(text_plot['file_path'])\n",
    "            if text_plot_content:\n",
    "                text_plot_data = self.extract_with_vertex_ai(text_plot_content, project_id)\n",
    "                if text_plot_data:\n",
    "                    # Prioritize bearing capacity and foundation type from text plot\n",
    "                    for key in ['bearing_capacity', 'foundation_type']:\n",
    "                        if text_plot_data.get(key) is not None:\n",
    "                            project_data[key] = text_plot_data[key]\n",
    "        \n",
    "        # Process Complete Report (for lab data and soil properties)\n",
    "        if complete_report:\n",
    "            print(f\"  üìä Analyzing Complete Report...\")\n",
    "            complete_report_content = self.extract_pdf_text_comprehensive(complete_report['file_path'])\n",
    "            if complete_report_content:\n",
    "                complete_report_data = self.extract_with_vertex_ai(complete_report_content, project_id)\n",
    "                if complete_report_data:\n",
    "                    # Add all lab data from complete report\n",
    "                    for key, value in complete_report_data.items():\n",
    "                        if value is not None and key not in project_data:\n",
    "                            project_data[key] = value\n",
    "        \n",
    "        return project_data\n",
    "    \n",
    "    def create_dataset(self) -> pd.DataFrame:\n",
    "        \"\"\"Create dataset using Vertex AI extraction\"\"\"\n",
    "        print(f\"\\nüöÄ Creating Vertex AI Geotechnical Dataset\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Identify files\n",
    "        self.identify_file_types()\n",
    "        \n",
    "        if not self.complete_reports and not self.text_plots:\n",
    "            print(\"‚ùå No PDF files found!\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Process each project\n",
    "        all_projects = []\n",
    "        \n",
    "        # Get unique project IDs\n",
    "        project_ids = set()\n",
    "        for cr in self.complete_reports:\n",
    "            project_ids.add(cr['project_id'])\n",
    "        for tp in self.text_plots:\n",
    "            project_ids.add(tp['project_id'])\n",
    "        \n",
    "        print(f\"\\nüîÑ Processing {len(project_ids)} projects with Vertex AI...\")\n",
    "        \n",
    "        for project_id in sorted(project_ids):\n",
    "            try:\n",
    "                project_data = self.process_project(project_id)\n",
    "                all_projects.append(project_data)\n",
    "                \n",
    "                # Add delay to respect API rate limits\n",
    "                time.sleep(2)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error processing project {project_id}: {e}\")\n",
    "                all_projects.append({'project_id': project_id})\n",
    "        \n",
    "        # Create DataFrame\n",
    "        dataset = pd.DataFrame(all_projects)\n",
    "        \n",
    "        print(f\"\\n‚úÖ Vertex AI dataset created: {dataset.shape[0]} projects √ó {dataset.shape[1]} features\")\n",
    "        \n",
    "        return dataset\n",
    "    \n",
    "    def save_dataset(self, df: pd.DataFrame, filename: str = 'geotechnical_dataset_vertex_ai.csv'):\n",
    "        \"\"\"Save enhanced dataset\"\"\"\n",
    "        df.to_csv(filename, index=False)\n",
    "        print(f\"\\nüíæ Dataset saved as: {filename}\")\n",
    "        \n",
    "        # Generate summary\n",
    "        print(f\"\\nüìä VERTEX AI EXTRACTION SUMMARY:\")\n",
    "        print(f\"   Projects processed: {len(df)}\")\n",
    "        print(f\"   Features extracted: {len(df.columns) - 1}\")\n",
    "        \n",
    "        # Feature completeness\n",
    "        for col in df.columns:\n",
    "            if col != 'project_id':\n",
    "                non_null = df[col].notna().sum()\n",
    "                total = len(df)\n",
    "                coverage = (non_null/total)*100\n",
    "                status = \"‚úÖ\" if coverage >= 75 else \"‚ö†Ô∏è\" if coverage >= 25 else \"‚ùå\"\n",
    "                print(f\"   {status} {col:<25}: {non_null}/{total} ({coverage:.0f}%)\")\n",
    "        \n",
    "        return df\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    print(\"üöÄ VERTEX AI GEOTECHNICAL DATA EXTRACTION SYSTEM\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Initialize extractor\n",
    "    try:\n",
    "        extractor = VertexAIGeotechnicalExtractor(\n",
    "            data_directory=\"Data\",\n",
    "            credentials_file=\"aiml-365220-a4deab52698f.json\"\n",
    "        )\n",
    "        \n",
    "        if not extractor.model:\n",
    "            print(\"‚ùå Vertex AI model not available. Exiting.\")\n",
    "            return None\n",
    "        \n",
    "        # Create enhanced dataset\n",
    "        dataset = extractor.create_dataset()\n",
    "        \n",
    "        if dataset.empty:\n",
    "            print(\"‚ùå No data extracted!\")\n",
    "            return None\n",
    "        \n",
    "        # Save results\n",
    "        extractor.save_dataset(dataset)\n",
    "        \n",
    "        # Display results\n",
    "        print(f\"\\nüìã DATASET PREVIEW:\")\n",
    "        print(dataset.head())\n",
    "        \n",
    "        print(f\"\\nüéØ READY FOR AI/ML MODELING!\")\n",
    "        \n",
    "        return dataset\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Extraction failed: {e}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ü§ñ EXECUTING VERTEX AI EXTRACTION PIPELINE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    results = main()\n",
    "    \n",
    "    if results is not None:\n",
    "        print(f\"\\nüéâ SUCCESS! Vertex AI extraction completed!\")\n",
    "        print(f\"üìä Dataset shape: {results.shape}\")\n",
    "    else:\n",
    "        print(\"‚ùå Extraction failed\")\n",
    "    \n",
    "    print(f\"\\nüèÅ PIPELINE COMPLETE!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
